{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c56ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install torchsummary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7966420",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "data=pd.read_csv(\"train (2).csv\")\n",
    "data=pd.read_csv(\"test (2).csv\")\n",
    "data=pd.read_csv(\"gender_submission (1).csv\")\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57121e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution2D, MaxPooling2D, BatchNormalization, Flatten, Dense, Dropout\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "config = tf.ConfigProto( device_count = {'GPU': 1 , 'CPU': 56} ) \n",
    "sess = tf.Session(config=config) \n",
    "keras.backend.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01463023",
   "metadata": {},
   "outputs": [],
   "source": [
    "S=64\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "\n",
    "trainDatagen = ImageDataGenerator(\n",
    "                    rescale=1./255,\n",
    "                    shear_range=0.2,\n",
    "                    zoom_range=0.2,\n",
    "                    horizontal_flip=True)\n",
    "\n",
    "testDatagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "trainDataset = trainDatagen.flow_from_directory(\n",
    "        'E:\\DSspecialization\\capstone project1',\n",
    "        target_size=(S, S),\n",
    "        batch_size=32,\n",
    "        class_mode='binary')\n",
    "\n",
    "testDataset = testDatagen.flow_from_directory(\n",
    "        'E:\\DSspecialization\\capstone project1',\n",
    "        target_size=(S, S),\n",
    "        batch_size=32,\n",
    "        class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26b0d6fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9861444",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.add(Convolution2D(filters=32, kernel_size=(3,3), strides=(1,1), input_shape=(64,64,3), activation='relu', padding='same'))\n",
    "\n",
    "classifier.add(MaxPooling2D(pool_size=(2,2), strides=(2,2) ))\n",
    "classifier.add(BatchNormalization())\n",
    "classifier.add(Convolution2D(filters=16, kernel_size=(3,3), strides=(1,1), activation='relu', padding='same'))\n",
    "\n",
    "\n",
    "classifier.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
    "\n",
    "\n",
    "classifier.add(BatchNormalization())\n",
    "\n",
    "\n",
    "classifier.add(Dropout(0.2))\n",
    "\n",
    "classifier.add(Convolution2D(filters=32, kernel_size=(3,3), strides=(2,2), activation='relu', padding='same'))\n",
    "\n",
    "\n",
    "classifier.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
    "\n",
    "\n",
    "classifier.add(BatchNormalization())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d46b33a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.add(Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b371afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.add(Dense(units=32,activation='relu'))\n",
    "classifier.add(Dense(units=1,activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd0623c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classifier.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc4e0d68",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "classifier.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "history = classifier.fit_generator(trainDataset,\n",
    "                         steps_per_epoch=8005,\n",
    "                         epochs=10,\n",
    "                         validation_data=testDataset,\n",
    "                         validation_steps=2000,\n",
    "                         verbose = 1)\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9058048",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "epochs=range(1,45)\n",
    "plt.plot(history.history['accuracy'],'green',label='Accuracy')\n",
    "plt.plot(history.history['loss'],'red',label='Loss')\n",
    "plt.title('Training Accuracy & Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.figure()\n",
    "plt.plot(history.history['val_accuracy'],'green',label='Accuracy')\n",
    "plt.plot(history.history['val_loss'],'red',label='Loss')\n",
    "plt.title('Validation Accuracy & Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.figure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13083735",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import tensorflow\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "img1 = image.load_img('cat.1.jpg', target_size=(64, 64))\n",
    "img = image.img_to_array(img1)\n",
    "img = img/255\n",
    "\n",
    "img = np.expand_dims(img, axis=0)\n",
    "prediction = classifier.predict(img, batch_size=None,steps=1) #gives all class prob.\n",
    "if(prediction[:,:]>0.5):\n",
    "    value ='Cat :%1.2f'%(prediction[0,0])\n",
    "    plt.text(20, 62,value,color='red',fontsize=18,bbox=dict(facecolor='white',alpha=0.8))\n",
    "else:\n",
    "    value ='Dog :%1.2f'%(1.0-prediction[0,0])\n",
    "    plt.text(20, 62,value,color='red',fontsize=18,bbox=dict(facecolor='white',alpha=0.8))\n",
    "\n",
    "plt.imshow(img1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "75cf2214",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating submission.csv file...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'test_ds' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[66], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGenerating submission.csv file...\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 4\u001b[0m test_ids_ds \u001b[38;5;241m=\u001b[39m \u001b[43mtest_ds\u001b[49m\u001b[38;5;241m.\u001b[39mmap(\u001b[38;5;28;01mlambda\u001b[39;00m image, idnum: idnum)\u001b[38;5;241m.\u001b[39munbatch()\n\u001b[0;32m      5\u001b[0m test_ids \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28miter\u001b[39m(test_ids_ds\u001b[38;5;241m.\u001b[39mbatch(NUM_TEST_IMAGES)))\u001b[38;5;241m.\u001b[39mnumpy()\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mU\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      7\u001b[0m np\u001b[38;5;241m.\u001b[39msavetxt(\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msubmission.csv\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m      9\u001b[0m     np\u001b[38;5;241m.\u001b[39mrec\u001b[38;5;241m.\u001b[39mfromarrays([test_ids, predictions]),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     13\u001b[0m     comments\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     14\u001b[0m )\n",
      "\u001b[1;31mNameError\u001b[0m: name 'test_ds' is not defined"
     ]
    }
   ],
   "source": [
    "print('Generating submission.csv file...')\n",
    "\n",
    "\n",
    "test_ids_ds = test_ds.map(lambda image, idnum: idnum).unbatch()\n",
    "test_ids = next(iter(test_ids_ds.batch(NUM_TEST_IMAGES))).numpy().astype('U')\n",
    "\n",
    "np.savetxt(\n",
    "    'submission.csv',\n",
    "    np.rec.fromarrays([test_ids, predictions]),\n",
    "    fmt=['%s', '%d'],\n",
    "    delimiter=',',\n",
    "    header='id,label',\n",
    "    comments='',\n",
    ")\n",
    "\n",
    "\n",
    "!head submission.csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b29e4a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "860c7fd7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
